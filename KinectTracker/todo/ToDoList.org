#+STARTUP: showall

* Treffen
  + [X] <2014-06-30 Mo 11:00>
    + Ort :: Lehrstuhl
    + Fragen
      + [X] Frage nach einer BA-Arbeit, wo eine Schätzung der Körpergröße
        über die Größe des Oberkörpers durchgeführt wurde.
        *Antwort*: Gab es bisher nicht am Lehrstuhl.
      + [X] Meiner Meinung nach ist ein Detektion auf Basis der Hautfarbe
        nicht zielführend, da keine Hautfarbe detektiert wird, sobald:
        1. sich die Person umdreht
        2. die Person mit dem Geischt zum Boden liegt
        Darüberhinaus werden nicht zum Körper gehörende Teile im Bild
        erkannt.
        *Antwort*: Dieses Verfahren soll nur benutzt werden, um die Blick-
        richtung der Person zu identifizieren.
        Sind genug Pixel hautfarben, schaut die Person in die Kamera, 
        ansonsten nicht.
  + [X] <2014-07-07 Mo 17:00> 
    + Ort :: Lehrstuhl
    + *Fragen*
      + [ ] Könnte Weichzeichnen die Ergebnisse der Rückprojektion verbessern?
  + [X] <2014-07-21 Mo 15:00> verschoben auf <2014-07-24 Do 16:00>
  + [ ] <2014-08-04 Mo 09:00>
    + Lauffähige, stabile Version
      + Nur eine Person, die auch nicht wechselt.
    + Inhaltsverzeichnis
  + [ ] <2015-08-17 Mo 15:00>
    + *Fragen*
      + [ ] Was genau kommt in das Algorithmenverzeichnis und was in
	das Quellcodeverzeichnis.

* Fähigkeiten der aktuellen Version
  + Tracking einer einzelen Person, nach dem die initialisierten Parameter 
    bestätigt wurden.
  + Klassifizierung des Zustands des Arbeiters in eine der folgenden Klassen
    + Stehend
    + Kniend
    + Liegend
    + Keine Klassifizierung möglich
  + Ableitung der Bewegungsrichtung und Geschwindigkeit.
  + Beurteilung, ob die Person in die Kamera schaut oder nicht.

* Schlachtplan
  1) [X] Stabile Version.
  2) [X] Reset ausschalten.
  3) [ ] Inhaltsangabe (1. Entwurf liegt vor)
  4) [ ] Initialisierungsphase.
     Falls die Koordinaten der Ebene und das Histogramm nicht bekannt 
     sind, sollen nur die von der Kinect empfangenen Skelett-, RGB-, Tiefendaten
     angezeigt werden.
     
     Sobald die Initialisierung beginnt, wird nur die Ebenengleichung 
     und das Histogramm bestimmt und die Bild- bzw. Skelettdaten
     die von der Kinect aufgenommenen Daten angezeigt.

     Nach Abschluss der Initialisierung werden dann die Analyse Ergebnisse 
     eingeblendet und aktuallisiert.

     + [ ] Ebenennormale alternativ bestimmen.
     + *Auslöser*: MainWindow::StartProcessing()
     + *Workflow*: 
       + Zeige die bestimmten Werte an.
	 + Werte
	 + Grafisch (Ausschnitt vom Kopf)
       + Biete Möglichkeit zum Abbruch.
	 + *Fall* Keine Ebenengleichung kein Histogramm vom Kopf.
	   + Hinweis: Verarbeitung ist unmöglich.
	 + *Fall* Kein Histogramm vom Kopf.
	   + 1. Möglichkeit: Hinweis: Verarbeitung nicht möglich.
	   + 2. Möglichkeit: Standardhistogramm laden.
	 + *Fall* Keine Ebenengleichung
	   + Standardebene initialisieren (falls nicht vorhanden).
	   + Hinweis: Ebene muss manuell eingestellt werden.
  5) [ ] Einfaches austauschen der Sizeanalyzer bzw. Movementanlayzer.
  6) [ ] Es ist extrem dumm, die zusätzlichen Daten, die beim kopieren der
     Tiefen- bzw. RGB-Daten vorhanden sind fortzuwerfen. Besser gemeinsam in einer
     Datenstruktur speichern.
  7) [X] RGB- und Tiefenbild permanent updaten.
     *Problem*: Sobald das ganze Bild untersucht wird, wird zu vile Zeit 
                beansprucht, sodass das Bild nicht mehr gerendert wird.
     *Lösung*: cv::imshow() scheint richtig zu funktionieren, evtl. 
               sollte auf die Texturen verzichtet werden und stattdessen
               cv::imshow() verwendet werden.
               Ggfs. lässt sich ein solches Fenster in Qt einbetten.
  
* TODO [18/35][51%] Tasks
  + [ ] RGB Bild wird nicht aktuallisiert, wenn der Bereich untersucht wird.
  + [ ] Maussteuerung.
  + [ ] Kinect Klasse aufräumen.
  + [ ] UpperBoddySizeAnalyzer: Faktor bestimmen.
  + [-] Falls keine Skelettinformationen vorhanden:
    + [X] Untersuche die Joints des letztens Skeletts.
    + [X] Untersuche die ganze letzte Region.
    um den Kopf zu finden.
    + [ ] Koordinaten des gefundenen Bereichs in den Skelettraum transformieren
      und an den SizeAnalyser übergeben, um die Pose zu klassifizieren. Checke ob 
      die gefundenen Koordinaten in der letzten BoundingBox liegen.
  + [ ] Pfeil für die Bewegungsrichtung wieder einschalten.
  + [-] Detektion des Bodens.
    + [ ] Mittels PCL
    + [ ] Manuelle Einstellung, falls die anderen Methoden versagen.
      Problem: Gimbal-Lock mit Roll/Pitch/Yaw wenn die Ebene nach dem Normalenvektor ausgerichtet
      werden soll -> Quartanionen.
    + [X] Mittels Kinect SDK  http://msdn.microsoft.com/en-us/library/hh973078.aspx
  + [ ] Backprojection für alle Gelenke, wenn die Person liegt (evtl. hat die Person markante 
   Kleidung an, was die ermöglicht).
  + [-] Zusätzliches Kriterium für liegend:
    + [X] Abstand zwischen den Füßen und dem Kopf berechnen.
    + [ ] Threshold ermitteln.
  + [ ] Umbenennung:
    + [ ] BoundingGeometry -> Geometry
    + [ ] BoudingBox -> Cube
    + [ ] BoundingSphere -> Sphere
    + [ ] BoundingGeometryWithTimestamp -> GeometryWithTimestamp
  + [ ] Skalierung des getrackten Bereiches, wenn sich der Mensch der Kamera nähert.
  + [-] [50%] Features für den Analysedialog
    + [X] [100%] Funktionen:
      - [X] Bild laden
      - [X] Region für das Histogram auswählen
      - [X] Histogram berechnen ( mittels LowLewevelProcessingPipeline )
      - [X] Histogram speichern in externe Datei / in Buffer
      - [X] Histogram vergleichen und Regionen einzeichnen
    + [ ] Probleme:
      - [ ] Resize-Verhalten ist scheiße.
  + [ ] Kinect connect/disconnect Signal.
    http://msdn.microsoft.com/en-us/library/nuiapi.nuisetdevicestatuscallback.aspx
  + [ ] Verschiebe das Zeichnen des Skelettes in die Visualizer Klasse.
  + [ ] Berechnung dafür, ob der Oberkörper aufrecht ist ( über Winkel ) vs. Länge der Glieder.
  + [ ] Infrarotdaten anschauen - IR anschauen ( Auflösung 640*480 )
    http://msdn.microsoft.com/en-us/library/jj663865.aspx
  + [X] Biete  Möglichkeit die Bewegungsrichtung und die Geschwindigkeit zu ermitteln durch Kugeln berechnen
    zu lassen
  + [-] Zusätzliche Feature [2/6][33%]
    + [ ] Speichernfunktion für ProcessingComponents und ProcessingPipeline
    + [X] Pause/Wiedergabe des Streams.
    + [ ] Schließen der Windows ermöglichen
    + [ ] Verbindungsdialog zu Kinect / USB-Kamera fertig stellen
    + [X] Affine Transformation ausbessern
    + [ ] Skelett Merkmalsvektor berechnen
  + [X] Farbhistogramm für Gelenke und Gesicht berechnen.
    Für das Gesicht gibt es 3 Möglichkeiten:
    1. [X] Farbbereich aus dem Paper.
    2. [X] Histogramm aus den LiveDatan ableiten, wenn sicher ist, dass der Kopf getrackt wird.
       + [X] Histogram vergleich
	 1. [[http://docs.opencv.org/trunk/doc/py_tutorials/py_imgproc/py_histograms/py_histogram_backprojection/py_histogram_backprojection.html][opencv]]
	 2. [[http://scien.stanford.edu/pages/labsite/2002/psych221/projects/02/sojeong/][Methodik]]
    3. [X] Gesichtserkennungsalgorithmus von opencv benutzen
     das der Mensch in die Kamera guckt.
  + [-] Umstellen auf das neue Eigenschaften-Widget [3/4][75%]
    + [-] Verbleibende Datentypen einfügen
      + [X] Vector<float>
      + [ ] Enumeration : Funktioniert leider nicht so einfach.
      + [ ] Vector<QColor>
    + [X] Synchronisation der Ansicht durch Änderungen in den Daten implementieren
    + [X] Umbennnen TreeWidgetExplorer -> PropertyBrowser
    + [X] altes Eigenschaften-Widget durch das neue ersetzen
  + [X] Bugfix für fixed skin region detection. Einschränkung auf den Bildbereich und nicht 
    auf das gesamte Bild.
  + [X] Trackingstatus der einzelnen Joints anzeigen.
  + [X] Arbeiter - Zustand Beurteilung verbessern [3/3][100%]
    Hat sich größten Teils erledigt, dadurch dass die Größe durch den Abstand von Kopf zum Fußboden
    ermittelt werden kann.
    + [X] Größe des Arbeiters über die Höhe des Oberkörpers abschätzen
    + [X] In der bestehenden Größenschätzung die Arme aus der Berechnung ausschließen
    + [X] Für die Schätzung der aktuellen Größe die Anzahl der getrackten Punkte mit einbeziehen
  + [X] Nutze die Proportionen des Körpers aus, um die Größe der Person zu 
    bestimmen, wenn sie nahe an der Kamera steht. Also ggfs. nur Knie in
    die Berechnung mit einbeziehen und die Füße außen vor lassen. Dasselbe
    gilt, für den Fall, dass keine Knie sichtbar sind.
    *Lösung*: Ist nicht mehr notwedig, da die Größe der Person jetzt über die Distanz vom Kopf 
    zum Boden ermittelt wird.
  + [X] Renderreihenfolge ist falsch, das Skelett wird vor der Ebene gezeichnet.
    Grund: OpenGL Depth Testing war nicht aktiviert.
  + [X] Rechtecke, die in cv::Mat gezeichnet werden sollen, müssen abgeschnitten werden,
    falls sie die Größe überschreiten (Cropping).
  + [X] Abastand von Boden zu Kopf kontinuierlich berechnen.
    [[http://www.frustfrei-lernen.de/mathematik/abstand-punkt-zu-ebene.html][Gleichung: Abstand Punkt zur Ebene]]
  + [X] Ersetze unsichere Array Kopierfunktion durch eine sichere.
  + [X] Meldung wenn der Benutzer zu nahe an der Kamera ist.
  + [X] SceneGraph anpassen.
  + [X] Worker Status wird nicht mehr angezeigt.
  + [X] Explorer-Klasse aus dem Projekt entfernen
  + [X] Signale gezielt unterbrechen und nicht in den Settern prüfen, ob die Werte gleich sind.
    + [X] Führe eine Helper-Klasse ein, die die Verbindung kurz unterbricht und im Destruktor
      wiederherstellt.
  + [X] Datei BoundingBoxes in BoundingGeometries umbennen.
  + [X] Kommunikation zwischen SkeletonAnalyzer und AnalysisResults optimieren.
    Viele der Properties aus SkeletonAnalyzer müssen read only sein.
  + [X] Dateien entfernen
    + [X] Explorer
    + [X] ImageAnalyzer
    + [X] RGBAnylzer
    + [X] AnalysisResults
** Refactoring
  + [ ] Erode anpassen
  + [ ] Dilate anpassen 

*** Anregungen
    + ViolaJones  

**** Erkenntnisse
     + Nach http://malen-malerei.de/proportionsregel-menschen-zeichnen soll die Größe des
       Oberkörpers 3/8 der gesamten Körpergröße betragen. Dies kommt leider nicht hin.
       Der Wert muss deshalb empirisch ermittelt und an verschiedenen Menschen evaluiert 
       werden.
     + Sobald der vorgschriebene Mindestabstand unterschritten wird, sind die gelieferten Daten 
       unzuverlässig.
     + Skelett-Space ist in Metern.
     + Tiefendataen sind in Milimetern.
     + Farbräume
       + HSV ( Hue Saturation Value):
       	 + Hue: Farbwert
       	 + Saturation: Farbsättigung
	   - 0% Neutralgrau
	   - 50% Wenig gesättigte Farbe
	   - 100% Gesättigte Farbe / reine Farbe
       	 + Value: Hellwert bzw. Dunkelstue
	   - 0% keine Helligkeit
	   - 100% volle Helligkeit
* Ausarbeitung
  + Vorraussetzung für das Funktionieren:
    + Kamera ist vernünftig positioniert:
      - Parallel zum Boden
      - Positive y-Richtung des Kinect-Sensors zeigt von Fuß zu Kopf.
    + Person ist vollständig sichtbar.
  + Kinect Sensor erklären
    + Verschiedene Sensoren und ihre Räume erläutern.
      + RGB
      + Tiefenbild in mm ( [[http://msdn.microsoft.com/en-us/library/hh973078.aspx][KinectSDK]] )
      + Skelettdaten in meter / Kooordinaten System zeiegn
  + Skelettgliederung
    + Bild: [[http://www.codeproject.com/KB/dotnet/KinectGettingStarted/7.png][Kinect-Skelett]]
  + Verschiedene [[http://docs.opencv.org/modules/imgproc/doc/histograms.html][Funktionen]] für den Vergleich von Histogrammen
    erklären, mit Formeln.
    + Korrelation
    + Chi-Quadrat
    + Intersect
    + Bhattacharyya
   Wurde nicht benutzt, stattdessen *backprojection*.
  + [[http://www.brinkmann-du.de/mathe/gost/bstat_01_03.htm][Histogramm]]
    + Häufigkeitsdichte = (relative Häufigkeit)/(Intervallbreite)
    + Summe alle Intervalle = 1
  + Floor determination / Schätzung des Fußbodens 
    + [[http://msdn.microsoft.com/en-us/library/hh973078.aspx][SDK]]
    + Alternative: RANSAC Algorithmus aus der PCL Bibliothek
    Die Erkennung der Bodens mittels der Tiefendaten funktioniert nicht so gut,
    an dieser Stelle ist eine manuelle Eingabe von nöten. Ist im Anwendungsfall 
    auch nicht weiter schlimm, da sich die Position des Sensor eigentlich nicht
    ändert.
  + BoundingBox-Algorithmus erläutern.
    + Zweck: Eingrenzung des Suchbereichs.
    + Grenzen: Verlassen des Bildbereiches.
  + Falls die Person liegt, kann sie sich durch kriechen "rausschleichen", d.h.
    das Programm nimmt an, der Arbeiter liegt, obwohl er gar nicht 
    mehr in der Szene ist.
  + SizeAnalyzer:
    Die Klassifizierung der Bewegungszustände funktioniert nur unter der Annahme,
    das die Person keinen Kopfstand macht.
    + *Frage* :  Macht das BoundingBox-Verfahren Sinn?
      + *Antwort* :

